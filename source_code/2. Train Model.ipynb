{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x25b7213aea0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "from functions import LoadEncoderDecoder, progress\n",
    "from create_pytorch_dataset import CustomImageDataset\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## VARIABLES ##########\n",
    "encoder_dictionary_filename = 'image_decoder.pkl'   # File to save the encoder and decoder\n",
    "datasource_filepath = 'cleaned_data/training_data.csv'    # File to save the training data\n",
    "cleaned_img_dir = 'cleaned_data/images/'  # Folder containing the cleaned images\n",
    "final_size = 224    # Final size of the images\n",
    "batch_size = 64    # Batch size for the DataLoader, \n",
    "\n",
    "# Paths to save the training, validation and test datasets\n",
    "train_indices_file = 'datasets/train_indices.pt'\n",
    "val_indices_file = 'datasets/val_indices.pt'\n",
    "test_indices_file = 'datasets/test_indices.pt'\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': v2.Compose([\n",
    "        v2.ToImage(), # Convert to tensor, only needed for PIL images\n",
    "        v2.RandomResizedCrop(size=(final_size, final_size), antialias=True),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        # v2.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "        # v2.RandomRotation(20),\n",
    "        v2.ToDtype(torch.float32, scale=True), # this has replaced ToTensor()\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.255]),\n",
    "    ]),\n",
    "    'val': v2.Compose([\n",
    "        v2.ToImage(), # Convert to tensor, only needed for PIL images\n",
    "        v2.Resize(256),\n",
    "        v2.CenterCrop(final_size),\n",
    "        v2.ToDtype(torch.float32, scale=True), # this has replaced ToTensor()\n",
    "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': v2.Compose([\n",
    "        v2.ToImage(),  # Convert to tensor, only needed for PIL images\n",
    "        v2.Resize(256),  # Resize to a standard size\n",
    "        v2.CenterCrop(final_size),  # Center crop to the final input size\n",
    "        v2.ToDtype(torch.float32, scale=True),  # Convert to tensor with dtype\n",
    "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with the same mean and std as training\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Loading encoder and decoder ##########\n",
      "\n",
      "\n",
      "########## Load Decoder Dictionary ##########\n",
      "----> Decoder dictionary loaded successfully\n",
      "----> Encoder and decoder extracted from the dictionary\n",
      "----> Encoder:\n",
      " {'Home & Garden': 0, 'Baby & Kids Stuff': 1, 'DIY Tools & Materials': 2, 'Music, Films, Books & Games': 3, 'Phones, Mobile Phones & Telecoms': 4, 'Clothes, Footwear & Accessories': 5, 'Other Goods': 6, 'Health & Beauty': 7, 'Sports, Leisure & Travel': 8, 'Appliances': 9, 'Computers & Software': 10, 'Office Furniture & Equipment': 11, 'Video Games & Consoles': 12}\n",
      "----> Decoder:\n",
      " {0: 'Home & Garden', 1: 'Baby & Kids Stuff', 2: 'DIY Tools & Materials', 3: 'Music, Films, Books & Games', 4: 'Phones, Mobile Phones & Telecoms', 5: 'Clothes, Footwear & Accessories', 6: 'Other Goods', 7: 'Health & Beauty', 8: 'Sports, Leisure & Travel', 9: 'Appliances', 10: 'Computers & Software', 11: 'Office Furniture & Equipment', 12: 'Video Games & Consoles'}\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder and decoder\n",
    "print('\\n########## Loading encoder and decoder ##########')\n",
    "encoder, decoder = LoadEncoderDecoder(encoder_dictionary_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Custom Image Dataset ##########\n",
      "----> Custom Image Dataset created\n",
      "----> Number of samples in the dataset: 12604\n"
     ]
    }
   ],
   "source": [
    "print('\\n########## Custom Image Dataset ##########')\n",
    "# Create the full dataset using training transformations (initially)\n",
    "full_dataset = CustomImageDataset(datasource_file=datasource_filepath, img_dir=cleaned_img_dir, transform=None)\n",
    "# full_dataset = CustomImageDataset(datasource_file=datasource_filepath, img_dir=cleaned_img_dir, transform=data_transforms['train'])\n",
    "print('----> Custom Image Dataset created')\n",
    "print(f\"----> Number of samples in the dataset: {len(full_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL - use smaller dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a smaller subset of the dataset for quick testing\n",
    "# small_dataset_size = 100  # Adjust as necessary\n",
    "# full_dataset = Subset(full_dataset, range(small_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the distribution of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of images per class: 691\n",
      "\n",
      "Number of images per label:\n",
      "1471 - Home & Garden\n",
      "1177 - Office Furniture & Equipment\n",
      "1136 - Computers & Software\n",
      "1088 - Health & Beauty\n",
      "1033 - Music, Films, Books & Games\n",
      "938 - DIY Tools & Materials\n",
      "917 - Appliances\n",
      "908 - Other Goods\n",
      "860 - Sports, Leisure & Travel\n",
      "828 - Video Games & Consoles\n",
      "786 - Phones, Mobile Phones & Telecoms\n",
      "771 - Clothes, Footwear & Accessories\n",
      "691 - Baby & Kids Stuff\n"
     ]
    }
   ],
   "source": [
    "# Count the number of images per label\n",
    "label_counts = full_dataset.img_labels['label'].value_counts()\n",
    "\n",
    "# Get the minimum number of images per class\n",
    "min_images_per_class = label_counts.min()\n",
    "print(f\"Minimum number of images per class: {min_images_per_class}\\n\")\n",
    "\n",
    "# Map label numbers to names using the decoder\n",
    "label_names = label_counts.index.map(decoder)\n",
    "\n",
    "# Print the number of images for each label\n",
    "print(\"Number of images per label:\")\n",
    "for label, count in zip(label_names, label_counts):\n",
    "    print(f\"{count} - {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide indices and save or load if previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Loading existing datasets...\n",
      "----> Existing Datasets loaded\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PiotrOgiela\\AppData\\Local\\Temp\\ipykernel_8592\\4153148049.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(filename)\n"
     ]
    }
   ],
   "source": [
    "# Function to save indices\n",
    "def save_indices(indices, filename):\n",
    "    # check if the folder exitsts and create if not\n",
    "    target_folder = filename.split('/')[0]\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "        print(f'----> Target folder created successfully: {target_folder}')\n",
    "        \n",
    "    # save the file\n",
    "    torch.save(indices, filename)\n",
    "    \n",
    "# Function to load indices\n",
    "def load_indices(filename):\n",
    "    return torch.load(filename)\n",
    "\n",
    "\n",
    "# Check if saved datasets exist\n",
    "if os.path.exists(train_indices_file) and os.path.exists(val_indices_file) and os.path.exists(test_indices_file):\n",
    "    print('----> Loading existing datasets...')\n",
    "    train_indices = load_indices(train_indices_file)\n",
    "    val_indices = load_indices(val_indices_file)\n",
    "    test_indices = load_indices(test_indices_file)\n",
    "    print('----> Existing Datasets loaded\\n')\n",
    "else:\n",
    "    print('----> Creating new datasets...')\n",
    "    # Group indices by class\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(full_dataset):\n",
    "        class_indices[label.item()].append(idx)\n",
    "    \n",
    "    # Calculate the minimum number of images per class\n",
    "    min_images_per_class = min(len(indices) for indices in class_indices.values())\n",
    "    train_limit = int(min_images_per_class * 0.95)  # 95% for training\n",
    "    \n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    for class_label, indices in class_indices.items():\n",
    "        random.shuffle(indices)  # Shuffle the indices\n",
    "        \n",
    "        train_indices.extend(indices[:train_limit])  # First 95% for training\n",
    "        remaining_indices = indices[train_limit:]    # Remaining 5%\n",
    "        half_remaining = len(remaining_indices) // 2\n",
    "        \n",
    "        val_indices.extend(remaining_indices[:half_remaining])  # 50% of remaining for validation\n",
    "        test_indices.extend(remaining_indices[half_remaining:]) # 50% of remaining for testing\n",
    "    \n",
    "    # Save the indices\n",
    "    save_indices(train_indices, train_indices_file)\n",
    "    save_indices(val_indices, val_indices_file)\n",
    "    save_indices(test_indices, test_indices_file)\n",
    "    print('----> Datasets saved successfully\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, validataion and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Dataset split into training, validation, and test sets completed\n",
      "----> Training dataset size: 8528\n",
      "----> Validation dataset size: 2035\n",
      "----> Test dataset size: 2041\n"
     ]
    }
   ],
   "source": [
    "# Create datasets using the loaded or newly created indices\n",
    "train_dataset = Subset(CustomImageDataset(datasource_file=datasource_filepath, img_dir=cleaned_img_dir, transform=data_transforms['train']), train_indices)\n",
    "val_dataset = Subset(CustomImageDataset(datasource_file=datasource_filepath, img_dir=cleaned_img_dir, transform=data_transforms['val']), val_indices)\n",
    "test_dataset = Subset(CustomImageDataset(datasource_file=datasource_filepath, img_dir=cleaned_img_dir, transform=data_transforms['test']), test_indices)\n",
    "\n",
    "print('----> Dataset split into training, validation, and test sets completed')\n",
    "print(f\"----> Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"----> Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"----> Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "########## Creating DataLoaders ##########\n",
      "----> DataLoaders created successfully\n",
      "----> Number of batches in the training DataLoader: 134\n",
      "----> Number of batches in the validation DataLoader: 32\n",
      "----> Number of batches in the test DataLoader: 32\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "print('\\n\\n########## Creating DataLoaders ##########')\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print('----> DataLoaders created successfully')\n",
    "print(f\"----> Number of batches in the training DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"----> Number of batches in the validation DataLoader: {len(val_dataloader)}\")\n",
    "print(f\"----> Number of batches in the test DataLoader: {len(test_dataloader)}\")\n",
    "\n",
    "# Create a dictionary of DataLoaders and dataset sizes\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "########## Preparing pretrained ResNet-50 model ##########\n",
      "----> Model loaded successfully\n",
      "----> Default number of features in the model: 2048\n",
      "----> Required number of classes in the model: 13\n",
      "----> Final linear layer replaced with required number of classess\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n########## Preparing pretrained ResNet-50 model ##########')\n",
    "# Load the pre-trained ResNet-50 model with the 'weights' parameter\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT) # Best available weights (currently alias for IMAGENET1K_V2)\n",
    "print('----> Model loaded successfully')\n",
    "\n",
    "# Disable gradients on all model parameters to freeze the weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Get the number of input features for the final linear layer\n",
    "num_features = model.fc.in_features\n",
    "print(f'----> Default number of features in the model: {num_features}')\n",
    "\n",
    "# Replace the final linear layer with a new one (`num_classes` is the number of categories)\n",
    "num_classes = len(encoder)  # Get the number of categories\n",
    "print(f'----> Required number of classes in the model: {num_classes}')\n",
    "\n",
    "# Replace the final linear layer\n",
    "\n",
    "# Adding dropout in a fully connected layer\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 1024),  # First linear layer (reduce dimensions)\n",
    "    nn.ReLU(),                     # ReLU activation\n",
    "    nn.Dropout(p=0.5),             # Dropout layer to prevent overfitting\n",
    "    nn.Linear(1024, num_classes)    # Final linear layer to match the number of classes\n",
    ")\n",
    "\n",
    "# model.fc = torch.nn.Linear(num_features, num_classes)   \n",
    "print(f'----> Final linear layer replaced with required number of classess')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing / Unfreezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Layers unfrozen\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the last few layers of the model\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(f'----> Layers unfrozen')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Model moved to cuda\n",
      "  ----> Current device number is: 0\n",
      "  ----> GPU name is: NVIDIA GeForce RTX 3060 Ti\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # Use the GPU if available\n",
    "model = model.to(device)    # Move the model to the device\n",
    "print(f\"----> Model moved to {device}\")   # Print the device\n",
    "if torch.cuda.is_available():\n",
    "    criterion.cuda()\n",
    "    devNumber = torch.cuda.current_device() # Get the current device number\n",
    "    print(f\"  ----> Current device number is: {devNumber}\") # Print the current device number\n",
    "    devName = torch.cuda.get_device_name(devNumber) # Get the device name\n",
    "    print(f\"  ----> GPU name is: {devName}\")    # Print the device name\n",
    "    \n",
    "print('-' * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0015, momentum = 0.875, weight_decay = 3.0517578125e-05)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 50, eta_min = 1E-6, last_epoch = -1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise tensorboard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard SummaryWriter\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_dir = f'model_evaluation/model_{timestamp}'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "weights_dir = os.path.join(model_dir, 'weights')\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    '''\n",
    "    Function to train the model\n",
    "    '''\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_params_path = 'best_model_params.pt'\n",
    "    torch.save(model.state_dict(), best_model_params_path)\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 75)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0           \n",
    "            \n",
    "            loop_no = 0\n",
    "            no_of_dataloaders = len(dataloaders[phase])\n",
    "            if phase == 'train':\n",
    "                print('----> Training:')\n",
    "            else:\n",
    "                print('----> Validation:')\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                loop_no += 1\n",
    "                \n",
    "                # Show progress for the epoch\n",
    "                progress(loop_no, no_of_dataloaders)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # print(f'  --> Loss: {loss.item()}')\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'\\n{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Log the loss and accuracy to TensorBoard\n",
    "            writer.add_scalar(f'{phase} Loss', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'{phase} Accuracy', epoch_acc, epoch)\n",
    "            \n",
    "            # Save the model weights at the end of each epoch\n",
    "            epoch_weights_path = os.path.join(weights_dir, f'epoch_{epoch}_weights.pth')\n",
    "            torch.save(model.state_dict(), epoch_weights_path)\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(torch.load(best_model_params_path))\n",
    "    writer.flush() # Flush the TensorBoard writer\n",
    "    writer.close()  # Close the TensorBoard writer\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 2.5182 Acc: 0.1795\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 2.4357 Acc: 0.3813\n",
      "\n",
      "Epoch 1/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 2.3303 Acc: 0.3610\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 2.1335 Acc: 0.4442\n",
      "\n",
      "Epoch 2/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.9654 Acc: 0.4212\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.7274 Acc: 0.4821\n",
      "\n",
      "Epoch 3/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.6901 Acc: 0.4655\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.5489 Acc: 0.5066\n",
      "\n",
      "Epoch 4/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.5274 Acc: 0.5032\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.4441 Acc: 0.5292\n",
      "\n",
      "Epoch 5/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.4415 Acc: 0.5254\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.3649 Acc: 0.5494\n",
      "\n",
      "Epoch 6/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.3545 Acc: 0.5563\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.3556 Acc: 0.5400\n",
      "\n",
      "Epoch 7/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.2891 Acc: 0.5796\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2950 Acc: 0.5695\n",
      "\n",
      "Epoch 8/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.2339 Acc: 0.5945\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2537 Acc: 0.5877\n",
      "\n",
      "Epoch 9/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.1731 Acc: 0.6155\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2306 Acc: 0.5990\n",
      "\n",
      "Epoch 10/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.1323 Acc: 0.6291\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2023 Acc: 0.6064\n",
      "\n",
      "Epoch 11/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.0809 Acc: 0.6466\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1832 Acc: 0.6152\n",
      "\n",
      "Epoch 12/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 1.0403 Acc: 0.6591\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1907 Acc: 0.6138\n",
      "\n",
      "Epoch 13/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.9930 Acc: 0.6742\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1914 Acc: 0.6103\n",
      "\n",
      "Epoch 14/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.9517 Acc: 0.6891\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1675 Acc: 0.6275\n",
      "\n",
      "Epoch 15/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.9323 Acc: 0.7004\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1465 Acc: 0.6310\n",
      "\n",
      "Epoch 16/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.8998 Acc: 0.7033\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1697 Acc: 0.6285\n",
      "\n",
      "Epoch 17/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.8495 Acc: 0.7213\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1675 Acc: 0.6354\n",
      "\n",
      "Epoch 18/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.8372 Acc: 0.7258\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1352 Acc: 0.6423\n",
      "\n",
      "Epoch 19/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.8028 Acc: 0.7393\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1455 Acc: 0.6408\n",
      "\n",
      "Epoch 20/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.7729 Acc: 0.7494\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1591 Acc: 0.6329\n",
      "\n",
      "Epoch 21/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.7593 Acc: 0.7530\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1784 Acc: 0.6442\n",
      "\n",
      "Epoch 22/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.7311 Acc: 0.7610\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1661 Acc: 0.6428\n",
      "\n",
      "Epoch 23/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.7119 Acc: 0.7669\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1706 Acc: 0.6403\n",
      "\n",
      "Epoch 24/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.6875 Acc: 0.7759\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1778 Acc: 0.6457\n",
      "\n",
      "Epoch 25/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.6833 Acc: 0.7818\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1704 Acc: 0.6486\n",
      "\n",
      "Epoch 26/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.6439 Acc: 0.7933\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1873 Acc: 0.6472\n",
      "\n",
      "Epoch 27/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.6411 Acc: 0.7934\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.1918 Acc: 0.6418\n",
      "\n",
      "Epoch 28/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.6121 Acc: 0.8036\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2245 Acc: 0.6354\n",
      "\n",
      "Epoch 29/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5978 Acc: 0.8090\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2160 Acc: 0.6477\n",
      "\n",
      "Epoch 30/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5923 Acc: 0.8119\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2245 Acc: 0.6496\n",
      "\n",
      "Epoch 31/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5778 Acc: 0.8134\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2400 Acc: 0.6486\n",
      "\n",
      "Epoch 32/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5692 Acc: 0.8167\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2183 Acc: 0.6550\n",
      "\n",
      "Epoch 33/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5535 Acc: 0.8221\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2323 Acc: 0.6486\n",
      "\n",
      "Epoch 34/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5520 Acc: 0.8240\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2394 Acc: 0.6506\n",
      "\n",
      "Epoch 35/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5599 Acc: 0.8172\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2602 Acc: 0.6482\n",
      "\n",
      "Epoch 36/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5479 Acc: 0.8265\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2645 Acc: 0.6516\n",
      "\n",
      "Epoch 37/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5325 Acc: 0.8309\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2647 Acc: 0.6369\n",
      "\n",
      "Epoch 38/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5291 Acc: 0.8315\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2698 Acc: 0.6452\n",
      "\n",
      "Epoch 39/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5364 Acc: 0.8289\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2436 Acc: 0.6511\n",
      "\n",
      "Epoch 40/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5131 Acc: 0.8383\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2729 Acc: 0.6442\n",
      "\n",
      "Epoch 41/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5159 Acc: 0.8344\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2598 Acc: 0.6477\n",
      "\n",
      "Epoch 42/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5057 Acc: 0.8412\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2392 Acc: 0.6526\n",
      "\n",
      "Epoch 43/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5307 Acc: 0.8284\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2523 Acc: 0.6511\n",
      "\n",
      "Epoch 44/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5275 Acc: 0.8336\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2581 Acc: 0.6477\n",
      "\n",
      "Epoch 45/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5151 Acc: 0.8327\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2652 Acc: 0.6536\n",
      "\n",
      "Epoch 46/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.4913 Acc: 0.8440\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2570 Acc: 0.6521\n",
      "\n",
      "Epoch 47/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5070 Acc: 0.8405\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2689 Acc: 0.6472\n",
      "\n",
      "Epoch 48/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5051 Acc: 0.8402\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2862 Acc: 0.6452\n",
      "\n",
      "Epoch 49/49\n",
      "---------------------------------------------------------------------------\n",
      "----> Training:\n",
      "[############################################################] 100.0%  [134 / 134]\n",
      "train Loss: 0.5080 Acc: 0.8423\n",
      "----> Validation:\n",
      "[############################################################] 100.0%  [32 / 32]\n",
      "val Loss: 1.2658 Acc: 0.6462\n",
      "\n",
      "Training complete in 85m 12s\n",
      "Best val Acc: 0.655037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PiotrOgiela\\AppData\\Local\\Temp\\ipykernel_8592\\1210758016.py:99: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_params_path))\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer, scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6389\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test dataset\n",
    "model_ft.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "for inputs, labels in test_dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc: {test_acc:.4f}')\n",
    "\n",
    "# Save test accuracy to a file\n",
    "test_metrics_path = os.path.join(model_dir, 'test_metrics.txt')\n",
    "with open(test_metrics_path, 'w') as f:\n",
    "    f.write(f'Test Accuracy: {test_acc:.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(img, mean, std):\n",
    "    \"\"\"\n",
    "    Unnormalize a tensor image with mean and std.\n",
    "    \"\"\"\n",
    "    img = img.clone()  # clone the tensor to avoid altering the original one\n",
    "    for t, m, s in zip(img, mean, std):\n",
    "        t.mul_(s).add_(m)  # scale by std and add the mean\n",
    "    return img\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    \"\"\"\n",
    "    Convert a tensor to a numpy array suitable for display.\n",
    "    \"\"\"\n",
    "    tensor = tensor.permute(1, 2, 0).numpy()  # Change to HWC format\n",
    "    tensor = np.clip(tensor, 0, 1)  # Clip to [0, 1] if necessary\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                                \n",
    "                # Convert tensor to numpy array and permute dimensions\n",
    "                img = inputs.cpu().data[j].permute(1, 2, 0).numpy()\n",
    "                \n",
    "                # Get the predicted and actual class names\n",
    "                predicted_class = decoder[preds[j].item()]\n",
    "                actual_class = decoder[labels[j].item()]\n",
    "                \n",
    "                # Set the title with both predicted and actual class\n",
    "                ax.set_title(f'Predicted: {predicted_class}\\nActual: {actual_class}')\n",
    "                plt.imshow(img)\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m visualize_model(\u001b[43mmodel_ft\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_ft' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_model(model_ft)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facebook_marketplace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
